# SSIM Loss 集成技术文档

> 日期: 2026-02-05
> 状态: 已实现, 已修复 VAE 集成 bug

---

## 1. 概述

在现有 MedQ-UNI 训练框架中集成 SSIM (Structural Similarity Index) loss, 作为 pixel loss (L1/L2) 的替代方案, 用于提升医学图像超分辨率/编辑任务的感知质量。

**核心思路**: SSIM 从亮度、对比度、结构三个维度衡量图像相似性, 比单纯的像素级 L2 loss 更贴近人眼感知。

### 支持的配置模式

| 模式 | pixel_loss_weight | ssim_loss_weight | 说明 |
|------|-------------------|------------------|------|
| Pixel only | >0 | 0 | 仅 L1/L2 像素损失 |
| SSIM only | 0 | >0 | 仅 SSIM 结构相似性损失 |
| 混合使用 | >0 | >0 | 两者同时启用 |

---

## 2. 修改的文件

### 2.1 `modeling/bagel/losses.py` — 新增函数

| 函数 | 作用 |
|------|------|
| `_gaussian_window(size, sigma, channels, device, dtype)` | 生成 SSIM 用的 2D 高斯窗口 |
| `_ssim_core(x, y, window, ...)` | SSIM 核心计算: 亮度 × 对比度 × 结构 |
| `compute_ssim_loss(x_pred, x_gt, mask, window_size)` | 计算 1 - SSIM 作为 loss (支持 mask) |
| `compute_perceptual_loss(...)` | 框架集成入口: 分块 VAE decode + timestep 过滤 + SSIM 计算 |

**SSIM 公式**:
```
SSIM(x, y) = (2*μx*μy + C1)(2*σxy + C2) / ((μx² + μy² + C1)(σx² + σy² + C2))
Loss = 1 - SSIM   (值域 [0, 1], 越小越好)
```

### 2.2 `modeling/bagel/bagel.py` — forward() 调用

- import 新增: `compute_perceptual_loss`
- forward() 新增参数: `ssim_loss_weight`, `ssim_loss_max_t`, `ssim_window_size`
- 在 pixel loss 计算之后, 独立调用 `compute_perceptual_loss()`
- 返回 dict 新增 `ssim` 字段: `dict(mse=mse, ce=ce, pixel=pixel, ssim=ssim)`
- 新增 SSIM 异常值安全检查 (NaN/Inf/大于1.0 则 clamp 为 0)

### 2.3 `train/main_sr_pixel_loss.py` — 训练循环

**新增 TrainingArguments 字段**:
```python
ssim_loss_weight: float = 0.0   # SSIM loss 权重 (>0 启用)
ssim_loss_max_t: float = 0.3    # 仅在 timestep t <= 此值时计算 SSIM
ssim_window_size: int = 11      # 高斯窗口大小
```

**训练循环改动**:
- loss 累加: `loss += ssim * training_args.ssim_loss_weight`
- 异常检测: NaN/Inf 检查 + all_reduce 前的 safety check
- TensorBoard 日志: 新增 `ssim_weighted` 指标

### 2.4 训练脚本

**新建**: `scripts/training/train_sft_stage1_medq_unif_multinode_eyeQ1_sr_ssim_loss.sh`
- Pixel loss 关闭 (`PIXEL_LOSS_WEIGHT=0`)
- SSIM loss 启用 (`SSIM_LOSS_WEIGHT=1.0`)
- 基于原脚本 `train_sft_stage1_medq_unif_multinode_eyeQ1_sr_pixel_loss_small_max_T_large_pixel_weight.sh` 修改

---

## 3. Bug 修复记录

### Bug: VAE 模型未集成 (TypeError: 'NoneType' object is not subscriptable)

**现象**: 使用 SSIM-only 配置运行时, `losses.py:1234` 报错:
```
x_pred_chunk = x_pred_chunk[:, :, :max_h_img, :max_w_img]
TypeError: 'NoneType' object is not subscriptable
```

**根因**: `train/main_sr_pixel_loss.py` 第 832 行, 决定是否将 VAE 集成到 Bagel 模型的条件:

```python
# 修复前 — 只检查 pixel_loss_weight
if training_args.visual_gen and (not training_args.freeze_vae or training_args.pixel_loss_weight > 0):

# 修复后 — 同时检查 ssim_loss_weight
if training_args.visual_gen and (not training_args.freeze_vae or training_args.pixel_loss_weight > 0 or training_args.ssim_loss_weight > 0):
```

**逻辑**: 当 `freeze_vae=True` 且 `pixel_loss_weight=0` 时, 原条件为 `False`, VAE 不会被集成到模型中 (`self.vae_model = None`). 新增 `ssim_loss_weight > 0` 检查后, SSIM-only 模式也能正确集成 VAE.

---

## 4. 关键参数说明

| 参数 | 默认值 | 说明 |
|------|--------|------|
| `ssim_loss_weight` | 0.0 | SSIM loss 权重, 设为 >0 启用 |
| `ssim_loss_max_t` | 0.3 | timestep 门控阈值, 仅 t <= 此值时计算 SSIM (低噪声步) |
| `ssim_window_size` | 11 | 高斯窗口大小, 用于局部相似性计算 |
| `SSIM_LOSS_DEBUG` | 0 | 环境变量, 设为 1 启用详细日志 |

### timestep 门控 (`ssim_loss_max_t`)

SSIM 只在低噪声 timestep 时计算, 因为高噪声步的去噪结果质量差, 强制 SSIM 约束没有意义。

权重公式:
```
w(t) = clamp((ssim_loss_max_t - t) / ssim_loss_max_t, 0, 1)
```
- `t = 0`: w = 1.0 (完全应用)
- `t = ssim_loss_max_t`: w = 0.0 (不应用)
- `t > ssim_loss_max_t`: w = 0.0 (不应用)

---

## 5. 运行方式

### SSIM-only 模式
```bash
bash scripts/training/train_sft_stage1_medq_unif_multinode_eyeQ1_sr_ssim_loss.sh
```

### 自定义参数
```bash
bash scripts/training/train_sft_stage1_medq_unif_multinode_eyeQ1_sr_ssim_loss.sh \
  "my_experiment_name" \  # $1: 实验名
  8 \                     # $2: GPU 数
  23456                   # $3: master port
```

### 启用调试日志
```bash
SSIM_LOSS_DEBUG=1 bash scripts/training/train_sft_stage1_medq_unif_multinode_eyeQ1_sr_ssim_loss.sh
```

---

## 6. 架构图

```
Training Loop (main_sr_pixel_loss.py)
  │
  ├─ fsdp_model(**data)
  │    │
  │    ▼
  │  Bagel.forward() (bagel.py)
  │    │
  │    ├─ compute_mse_loss()        → mse   (latent 空间)
  │    ├─ compute_pixel_loss()      → pixel  (像素空间 L1/L2)
  │    ├─ compute_perceptual_loss() → ssim   (像素空间 SSIM)
  │    └─ compute_ce_loss()         → ce     (语言模型)
  │
  ▼
  loss = ce * ce_weight
       + mse * mse_weight
       + pixel * pixel_loss_weight
       + ssim * ssim_loss_weight
```

**注意**: pixel loss 和 SSIM loss 各自独立执行 VAE decode, 不共享解码结果。如果两者同时启用, VAE decode 会执行两次。

---

## 7. SSIM Loss 计算思路详解

### 7.1 为什么用 SSIM 而不是 L2

L2 (MSE) pixel loss 的问题:
```
L2 = mean((x_pred - x_gt)^2)
```
- L2 对所有像素一视同仁, 一个均匀的模糊图和一个有轻微位移的清晰图, L2 可能给出相同的值
- 人眼对结构信息 (边缘、纹理) 远比对绝对亮度值更敏感
- 在医学图像中, 病灶边缘的清晰度比整体亮度更重要

SSIM 的优势:
- 分三个独立维度评价: **亮度** (luminance)、**对比度** (contrast)、**结构** (structure)
- 使用局部窗口统计, 捕捉空间上的结构关系
- 值域 [0, 1], 1 表示完全相同, 更符合直觉

### 7.2 SSIM 数学原理 + 代码实现

给定两张图 x (预测) 和 y (真实), 在每个局部窗口内:

```
亮度比较:  l(x,y) = (2*μx*μy + C1) / (μx² + μy² + C1)
对比度比较: c(x,y) = (2*σx*σy + C2) / (σx² + σy² + C2)
结构比较:  s(x,y) = (σxy + C2/2)  / (σx*σy + C2/2)

SSIM(x,y) = l(x,y) * c(x,y) * s(x,y)
```

实际计算中合并为一个公式:
```
SSIM = (2*μx*μy + C1)(2*σxy + C2) / ((μx² + μy² + C1)(σx² + σy² + C2))
```

其中:
- `μx, μy` = 局部均值 (通过高斯卷积计算)
- `σx², σy²` = 局部方差
- `σxy` = 局部协方差
- `C1 = (K1 * L)²`, `C2 = (K2 * L)²` 为稳定常数, L 是像素值域 (这里 L=1.0)
- K1=0.01, K2=0.03 是经验值

**Loss = 1 - SSIM**, 这样最小化 loss 就是最大化 SSIM.

**对应代码** — `_ssim_core()` (`modeling/bagel/losses.py:898-952`):
```python
def _ssim_core(x, y, window, window_size, channel,
               data_range=1.0, K1=0.01, K2=0.03):
    C1 = (K1 * data_range) ** 2   # 稳定常数 = 0.0001
    C2 = (K2 * data_range) ** 2   # 稳定常数 = 0.0009

    padding = window_size // 2

    # 高斯加权局部均值 μx, μy
    mu_x = F.conv2d(x, window, padding=padding, groups=channel)
    mu_y = F.conv2d(y, window, padding=padding, groups=channel)

    mu_x_sq = mu_x ** 2
    mu_y_sq = mu_y ** 2
    mu_xy = mu_x * mu_y

    # 局部方差 σx², σy² 和协方差 σxy
    # Var(X) = E[X²] - E[X]²
    sigma_x_sq = F.conv2d(x * x, window, padding=padding, groups=channel) - mu_x_sq
    sigma_y_sq = F.conv2d(y * y, window, padding=padding, groups=channel) - mu_y_sq
    sigma_xy   = F.conv2d(x * y, window, padding=padding, groups=channel) - mu_xy

    # 数值稳定: 方差不能为负
    sigma_x_sq = torch.clamp(sigma_x_sq, min=0)
    sigma_y_sq = torch.clamp(sigma_y_sq, min=0)

    # 最终 SSIM 公式
    numerator   = (2 * mu_xy + C1) * (2 * sigma_xy + C2)
    denominator = (mu_x_sq + mu_y_sq + C1) * (sigma_x_sq + sigma_y_sq + C2)
    ssim_map = numerator / (denominator + 1e-8)

    return ssim_map  # shape: (B, C, H, W), 每个位置的 SSIM 值
```

### 7.3 高斯窗口

**对应代码** — `_gaussian_window()` (`modeling/bagel/losses.py:870-895`):
```python
def _gaussian_window(window_size, sigma, channel, device, dtype):
    # 1D 高斯核: [-5, -4, ..., 0, ..., 4, 5]
    coords = torch.arange(window_size, device=device, dtype=dtype) - window_size // 2
    g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))
    g = g / g.sum()   # 归一化

    # 外积得到 2D 窗口 (11×11)
    window_2d = g.unsqueeze(1) @ g.unsqueeze(0)
    window_2d = window_2d / window_2d.sum()

    # 扩展到多通道: (C, 1, 11, 11) 用于 depthwise conv
    window = window_2d.unsqueeze(0).unsqueeze(0).expand(channel, 1, window_size, window_size)
    return window.contiguous()
```

使用 `F.conv2d(x, window, groups=C)` 做 depthwise 卷积, 相当于对每个通道独立计算加权局部均值。

### 7.4 SSIM Loss 入口函数

**对应代码** — `compute_ssim_loss()` (`modeling/bagel/losses.py:955-1043`):
```python
def compute_ssim_loss(x_pred, x_gt, mask=None, window_size=11,
                      data_range=1.0, K1=0.01, K2=0.03):
    B, C, H, W = x_pred.shape

    # 自适应窗口: 小图自动缩小窗口
    if H < window_size or W < window_size:
        window_size = max(3, min(H, W) | 1)  # 确保为奇数, 最小 3

    window = _gaussian_window(window_size, sigma=1.5, channel=C, ...)

    # 每个位置的 SSIM 值
    ssim_map = _ssim_core(x_pred, x_gt, window, window_size, C)

    # 有 mask 时: 加权平均 (timestep 门控权重)
    if mask is not None:
        if mask.shape[2:] != ssim_map.shape[2:]:
            mask = F.interpolate(mask, size=ssim_map.shape[2:], mode='bilinear')
        if mask.shape[1] == 1 and ssim_map.shape[1] > 1:
            mask = mask.expand(-1, ssim_map.shape[1], -1, -1)
        mean_ssim = (ssim_map * mask).sum() / (mask.sum() * C + 1e-8)
    else:
        mean_ssim = ssim_map.mean()

    # 1 - SSIM → loss (越小越好)
    ssim_loss = torch.clamp(1.0 - mean_ssim, min=0.0, max=1.0)
    return ssim_loss
```

### 7.5 Diffusion 训练中的完整流程 + 代码

SSIM loss 在 diffusion 框架中的计算需要多个步骤, 因为模型直接预测的不是图像, 而是 latent space 中的 velocity.

**对应代码** — `compute_perceptual_loss()` (`modeling/bagel/losses.py:1046-1288`):

#### 步骤 1: 从 LLM 输出预测 velocity
```python
# losses.py:1116-1118
velocity_pred = llm2vae(last_hidden_state[mse_loss_indexes])
velocity_target = noise_tokens - z0_tokens_clean
supervise_mask = t_tokens_all > 0
```

#### 步骤 2: 反推干净的 latent z0
```python
# losses.py:1122-1126
t_tokens_supervised = t_tokens_all[supervise_mask].to(z0_tokens_clean.dtype)

# flow matching 反推公式: z0_pred = z0 + t * (v_target - v_pred)
z0_tokens_pred = z0_tokens_clean[supervise_mask] \
    + t_tokens_supervised[:, None] * (velocity_target[supervise_mask] - velocity_pred)

# 混合: 无噪声的用 GT, 有噪声的用预测
z0_tokens_hybrid = z0_tokens_clean.clone()
z0_tokens_hybrid[supervise_mask] = z0_tokens_pred
```

#### 步骤 3: timestep 门控 — 选择哪些图参与 SSIM
```python
# losses.py:1134-1151
# 找到每张图的起始 token, 取其 timestep 作为整张图的 t
image_start_ptrs = torch.cat(
    [torch.zeros(1, ...), tokens_per_image_t.cumsum(0)[:-1]]
)
t_img = t_tokens_all[image_start_ptrs]

# 线性衰减权重: t 越小 (噪声越少) 权重越大
w_img[image_is_target] = torch.clamp(
    (ssim_loss_max_t - t_img[image_is_target]) / ssim_loss_max_t,
    min=0.0, max=1.0,
)
selected = w_img > 0   # 只有 t <= max_t 的图才参与

# 例: max_t = 0.3
#   t=0.1  → w=0.67  (参与, 高权重)
#   t=0.25 → w=0.17  (参与, 低权重)
#   t=0.5  → w=0     (不参与)
```

#### 步骤 4: 将 flat token 序列还原为 2D latent
```python
# losses.py:1170-1182
for img_idx, (h, w) in enumerate(patchified_vae_latent_shapes):
    num_img_tokens = h * w
    if selected[img_idx]:
        tok = z0_tokens_hybrid[token_ptr : token_ptr + num_img_tokens]
        # (h, w) 个 patch, 每个 patch 是 (p×p×c) 的向量
        tok = tok.view(h, w, p, p, c)
        # unpatchify: 重排为标准 latent 格式 (C, H*p, W*p)
        latent = torch.einsum("hwpqc->chpwq", tok).reshape(c, h*p, w*p)
        pred_latents.append(latent)

        # 从 padded_images 取对应 GT
        H_img = h * latent_downsample
        W_img = w * latent_downsample
        gt_images.append(padded_images[img_idx, :, :H_img, :W_img])
    token_ptr += num_img_tokens
```

#### 步骤 5: Pad + 分块 VAE decode
```python
# losses.py:1186-1234
# 统一 pad 到最大尺寸, 组成 batch
max_h_lat = max(z.shape[1] for z in pred_latents)
max_w_lat = max(z.shape[2] for z in pred_latents)
latent_batch = zeros((N, c, max_h_lat, max_w_lat))
gt_batch     = zeros((N, 3, max_h_img, max_w_img))
mask         = zeros((N, 1, max_h_img, max_w_img))

# 填入数据, mask 填入 timestep 权重
for i, (z, x_gt, w_i) in enumerate(zip(pred_latents, gt_images, weights)):
    latent_batch[i, :, :H_lat, :W_lat] = z
    gt_batch[i, :, :H_img, :W_img] = x_gt
    mask[i, :, :H_img, :W_img] = w_i   # 权重写入 mask

# 分块 decode 防 OOM
for chunk_idx in range(num_chunks):
    latent_chunk = latent_batch[start:end]
    x_pred_chunk = vae_decode_fn(latent_chunk)      # VAE 解码
    x_pred_chunk = x_pred_chunk[:, :, :max_h_img, :max_w_img]  # 裁 padding
```

#### 步骤 6: 归一化 + 计算 SSIM
```python
# losses.py:1237-1252
# VAE 输出 [-1, 1] → 转为 [0, 1]
x_pred_chunk_01 = (x_pred_chunk * 0.5 + 0.5).clamp(0, 1)
gt_chunk_01     = (gt_chunk     * 0.5 + 0.5).clamp(0, 1)

# 调用 SSIM loss (带 mask 加权)
chunk_ssim_loss = compute_ssim_loss(
    x_pred_chunk_01, gt_chunk_01,
    mask=mask_chunk, window_size=ssim_window_size,
)

# 按有效像素数量加权累加
chunk_weight = mask_chunk.sum()
ssim_numerator   += chunk_ssim_loss * chunk_weight
ssim_denominator += chunk_weight
```

#### 步骤 7: 安全检查 + 返回
```python
# losses.py:1260-1288
# 加权平均
if ssim_denominator > 1e-3:
    ssim_loss = ssim_numerator / ssim_denominator
else:
    ssim_loss = 0.0   # 没有有效样本

# 最终安全检查: NaN/Inf 或超出 [0,1] 范围 → clamp 为 0
if not torch.isfinite(ssim_loss) or ssim_loss > 1.0:
    ssim_loss = 0.0
return ssim_loss
```

### 7.6 bagel.py forward() 调用方式

**对应代码** — `Bagel.forward()` (`modeling/bagel/bagel.py:418-438`):
```python
# 在 pixel loss 之后, 独立调用 SSIM loss
ssim = compute_perceptual_loss(
    last_hidden_state=last_hidden_state,
    mse_loss_indexes=mse_loss_indexes,
    llm2vae=self.llm2vae,
    packed_latent_clean=z0_tokens_clean,
    noise=noise_tokens,
    packed_timesteps=t_tokens_all,
    padded_images=padded_images,
    patchified_vae_latent_shapes=patchified_vae_latent_shapes,
    packed_vae_token_indexes=packed_vae_token_indexes,
    vae_decode_fn=self.vae_decode,         # VAE 解码函数
    latent_patch_size=self.latent_patch_size,
    latent_channel=self.latent_channel,
    latent_downsample=self.latent_downsample,
    ssim_loss_weight=ssim_loss_weight,
    ssim_loss_max_t=ssim_loss_max_t,
    ssim_window_size=ssim_window_size,
    is_training=self.training,
)

# 返回所有 loss
return dict(mse=mse, ce=ce, pixel=pixel, ssim=ssim)
```

### 7.7 训练循环中的 loss 聚合

**对应代码** — `main()` (`train/main_sr_pixel_loss.py:1301-1321`):
```python
# 取出 ssim loss
ssim = loss_dict.get("ssim")
if ssim is not None:
    # 累加到总 loss
    loss += ssim * training_args.ssim_loss_weight

    # TensorBoard 日志
    # → 记录 ssim_weighted = ssim * weight
```

**VAE 集成条件** (`train/main_sr_pixel_loss.py:832`):
```python
# pixel loss 或 ssim loss 启用时, 即使 VAE 冻结也要集成 (需要 decode 能力)
if training_args.visual_gen and (
    not training_args.freeze_vae
    or training_args.pixel_loss_weight > 0
    or training_args.ssim_loss_weight > 0    # ← 修复: 新增此条件
):
    model = Bagel(..., vae_model=vae_model)  # VAE 集成到模型内
else:
    model = Bagel(..., vae_model=None)        # VAE 不集成
```

### 7.8 关键设计选择

| 设计点 | 选择 | 理由 |
|--------|------|------|
| 窗口大小 | 11×11 | SSIM 论文原始设定, 平衡局部性和稳定性 |
| sigma | 1.5 | 论文默认值 |
| 归一化范围 | [0, 1] | SSIM 假设非负输入, VAE 输出 [-1, 1] 需转换 |
| 分块 decode | chunk_size=2 | H200 显存充裕但仍防止极端 case OOM |
| timestep 门控 | max_t=0.3 | 高噪声步预测不准, SSIM 约束反而有害 |
| Loss = 1 - SSIM | 而非 -log(SSIM) | 梯度更稳定, 值域固定 [0, 1] |

### 7.9 与 Pixel Loss 的对比

```
                    Pixel Loss (L2)          SSIM Loss
─────────────────────────────────────────────────────────
比较方式            逐像素差的平方            局部窗口内的统计量
对模糊的惩罚        弱 (模糊可降低 L2)        强 (模糊破坏结构)
对亮度偏移          敏感                      不敏感 (有亮度归一化)
梯度来源            每个像素独立              通过局部统计耦合邻域
值域                [0, +inf)                [0, 1]
权重量级            需要大权重 (如 10000)      权重 ~1.0 即可
医学图像适用性      可接受                    更好 (关注结构细节)
```
