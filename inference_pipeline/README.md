# æ¨ç†æµç¨‹ (Inference Pipeline)

æœ¬ç›®å½•åŒ…å« MedQ-Uni æ¨¡å‹çš„æ‰¹é‡æ¨ç†è„šæœ¬ã€æ‰§è¡Œè„šæœ¬å’Œç»“æœç»Ÿè®¡å·¥å…·ã€‚

## ğŸ“ ç›®å½•ç»“æ„

```
inference_pipeline/
â”œâ”€â”€ MedQ-Uni_run_batch_test1.py          # Python æ‰¹é‡æµ‹è¯•è„šæœ¬ (VAE min=512)
â”œâ”€â”€ MedQ-Uni_run_batch_test2.py          # Python æ‰¹é‡æµ‹è¯•è„šæœ¬ (VAE min=256)
â”œâ”€â”€ MedQ-Uni_run_batch_test_ver1.sh      # Shell è„šæœ¬: å•æ£€æŸ¥ç‚¹æ¨ç†
â”œâ”€â”€ MedQ-Uni_run_batch_test_ver2.sh      # Shell è„šæœ¬: å¤šæ£€æŸ¥ç‚¹å¹¶è¡Œæ¨ç†
â”œâ”€â”€ parse_statistics_to_csv.py            # ç»Ÿè®¡ç»“æœèšåˆå·¥å…·
â””â”€â”€ README.md                             # æœ¬æ–‡æ¡£
```

## ğŸ“„ è„šæœ¬è¯´æ˜

### Python æµ‹è¯•è„šæœ¬

#### MedQ-Uni_run_batch_test1.py
- **åŠŸèƒ½**: æ‰¹é‡æ¨ç†æµ‹è¯•è„šæœ¬ï¼Œæ”¯æŒ PSNR/SSIM æŒ‡æ ‡è®¡ç®—
- **ç‰¹ç‚¹**: VAE transform min size = **512**
- **æ ¸å¿ƒç±»**:
  - `ImageGenerator`: æ¨¡å‹åŠ è½½å’Œå›¾åƒç”Ÿæˆ
  - `BatchTester`: æ‰¹é‡å¤„ç†ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
- **æŒ‡æ ‡è®¡ç®—**: `calculate_psnr()`, `calculate_ssim()`
- **è¾“å‡º**: `results.jsonl`, `statistics.json`, `images/`

#### MedQ-Uni_run_batch_test2.py
- **åŠŸèƒ½**: ä¸ test1.py ç›¸åŒçš„æ‰¹é‡æ¨ç†åŠŸèƒ½
- **ç‰¹ç‚¹**: VAE transform min size = **256**
- **å…¶ä»–**: ä¸ test1.py ä»£ç å‡ ä¹å®Œå…¨ç›¸åŒ

> **æ³¨æ„**: ä¸¤ä¸ªè„šæœ¬çš„å”¯ä¸€åŒºåˆ«åœ¨äº VAE transform çš„æœ€å°å°ºå¯¸é…ç½® (line 618)ï¼Œå½±å“å›¾åƒé¢„å¤„ç†çš„ä¸‹é‡‡æ ·ç­–ç•¥ã€‚

### Shell æ‰§è¡Œè„šæœ¬

#### MedQ-Uni_run_batch_test_ver1.sh
- **ç”¨é€”**: å•æ£€æŸ¥ç‚¹é¡ºåºæ¨ç†
- **ç‰¹ç‚¹**:
  - å•ä¸ªæ¨¡å‹æ£€æŸ¥ç‚¹ (0016000)
  - å• GPU æ‰§è¡Œ (GPU 3)
  - é¡ºåºå¤„ç†å¤šä¸ªæ•°æ®é›† (8 ä¸ªæµ‹è¯•é›†)
  - ç®€å•çš„å¾ªç¯æ‰§è¡Œ
- **è¾“å‡ºç›®å½•**: `MedQ-Uni_results_16000/{DATASET_NAME}_{TIMESTAMP}/`
- **é€‚ç”¨åœºæ™¯**: å¿«é€Ÿæµ‹è¯•å•ä¸ªæ£€æŸ¥ç‚¹ï¼Œè°ƒè¯•æ¨ç†æµç¨‹

#### MedQ-Uni_run_batch_test_ver2.sh
- **ç”¨é€”**: å¤šæ£€æŸ¥ç‚¹å¹¶è¡Œæ¨ç†
- **ç‰¹ç‚¹**:
  - å¤šä¸ªæ¨¡å‹æ£€æŸ¥ç‚¹ (5ä¸ª: 0004000, 0008000, 0012000, 0016000, 0020000)
  - å¤š GPU å¹¶è¡Œæ‰§è¡Œ (GPU 0, GPU 1)
  - å¤„ç†å¤šä¸ªæ•°æ®é›† (12 ä¸ªè®­ç»ƒé›†)
  - è½®è¯¢ä»»åŠ¡åˆ†é… (round-robin)
  - æ¯ä¸ªæ£€æŸ¥ç‚¹ç‹¬ç«‹æ‰§è¡Œï¼ŒGPU é—´å¹¶è¡Œ
  - è¯¦ç»†çš„æ—¥å¿—è®°å½• (æŒ‰ GPU å’Œæ£€æŸ¥ç‚¹åˆ†æ–‡ä»¶)
- **è¾“å‡ºç›®å½•**: `stage1_train_50_ver1/{CHECKPOINT_NAME}/{DATASET_NAME}/`
- **é€‚ç”¨åœºæ™¯**: æ‰¹é‡è¯„ä¼°å¤šä¸ªæ£€æŸ¥ç‚¹ï¼Œç”Ÿäº§ç¯å¢ƒå¤§è§„æ¨¡æ¨ç†

### ç»Ÿè®¡åˆ†æè„šæœ¬

#### parse_statistics_to_csv.py
- **åŠŸèƒ½**: èšåˆå¤šä¸ª `statistics.json` æ–‡ä»¶åˆ°ç»Ÿä¸€ CSV æ–‡ä»¶
- **å¤„ç†æµç¨‹**:
  1. é€’å½’æ‰«ææŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰ `statistics.json` æ–‡ä»¶
  2. ä»æ–‡ä»¶è·¯å¾„æå–å…ƒæ•°æ® (model_id, split)
  3. è§£æ overall å’Œ by_task_type æŒ‡æ ‡
  4. æ¨ªå‘å±•å¼€å¤šä»»åŠ¡ç±»å‹ (task1_*, task2_*, ...)
  5. ç”Ÿæˆç»Ÿä¸€çš„ CSV æ±‡æ€»è¡¨
- **è¾“å‡º**: `summary.csv` (åŒ…å«æ‰€æœ‰æ£€æŸ¥ç‚¹çš„æ€§èƒ½æŒ‡æ ‡)
- **é…ç½®**: å¯é€šè¿‡è„šæœ¬é¡¶éƒ¨çš„ `DEFAULT_INPUT_DIRECTORIES` ä¿®æ”¹é»˜è®¤è¾“å…¥è·¯å¾„

## ğŸ” ç‰ˆæœ¬å·®å¼‚å¯¹æ¯”

### test1.py vs test2.py

| ç‰¹æ€§ | test1.py | test2.py |
|------|----------|----------|
| **VAE Transform Min Size** | 512 | **256** |
| **ä»£ç è¡Œæ•°** | 816 | 813 |
| **æ ¸å¿ƒåŠŸèƒ½** | âœ… ç›¸åŒ | âœ… ç›¸åŒ |
| **ImageGenerator ç±»** | âœ… | âœ… |
| **BatchTester ç±»** | âœ… | âœ… |
| **PSNR/SSIM è®¡ç®—** | âœ… | âœ… |
| **æ–­ç‚¹ç»­ä¼ ** | âœ… | âœ… |

**å…³é”®åŒºåˆ«** (test2.py:618):
```python
# test1.py
vae_transform = ImageTransform(img_size=1024, min_size=512, num_buckets=16)

# test2.py
vae_transform = ImageTransform(img_size=1024, min_size=256, num_buckets=16)
```

**é€‰æ‹©å»ºè®®**:
- `min_size=256`: æ›´æ¿€è¿›çš„ä¸‹é‡‡æ ·ï¼Œé€Ÿåº¦æ›´å¿«ï¼Œæ˜¾å­˜å ç”¨æ›´å°ï¼Œå¯èƒ½æŸå¤±ç»†èŠ‚
- `min_size=512`: ä¿ç•™æ›´å¤šç»†èŠ‚ï¼Œæ˜¾å­˜å ç”¨æ›´å¤§ï¼Œæ¨ç†é€Ÿåº¦è¾ƒæ…¢

### ver1.sh vs ver2.sh

| ç‰¹æ€§ | ver1.sh | ver2.sh |
|------|---------|---------|
| **æ£€æŸ¥ç‚¹æ•°é‡** | 1 ä¸ª | 5 ä¸ª |
| **æ£€æŸ¥ç‚¹ç‰ˆæœ¬** | 0016000 | 0004000-0020000 |
| **GPU ä½¿ç”¨** | å• GPU (3) | åŒ GPU (0, 1) |
| **æ•°æ®é›†æ•°é‡** | 8 ä¸ª | 12 ä¸ª |
| **æ‰§è¡Œæ–¹å¼** | é¡ºåºæ‰§è¡Œ | å¹¶è¡Œæ‰§è¡Œ |
| **ä»»åŠ¡åˆ†é…** | N/A | è½®è¯¢ (round-robin) |
| **æ—¥å¿—ç®¡ç†** | æ ‡å‡†è¾“å‡º | ç‹¬ç«‹æ—¥å¿—æ–‡ä»¶ |
| **è¾“å‡ºç»“æ„** | æ‰å¹³ | æŒ‰æ£€æŸ¥ç‚¹åˆ†å±‚ |
| **è„šæœ¬è¡Œæ•°** | 139 | 291 |

**æ‰§è¡Œæµç¨‹å¯¹æ¯”**:

**ver1.sh**:
```
for æ¯ä¸ªæ•°æ®é›†:
    æ¨ç† -> ç­‰å¾…å®Œæˆ -> ä¸‹ä¸€ä¸ª
```

**ver2.sh**:
```
for æ¯ä¸ªæ£€æŸ¥ç‚¹:
    for æ¯ä¸ª GPU:
        åˆ†é…ä»»åŠ¡åˆ—è¡¨ -> åå°æ‰§è¡Œ
    ç­‰å¾…æ‰€æœ‰ GPU å®Œæˆ
    ç­‰å¾… 15 ç§’ (GPU æ¸…ç†)
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### å‰ç½®è¦æ±‚

1. **ç¯å¢ƒæ¿€æ´»**:
   ```bash
   cd /mnt/shared-storage-user/quwanying/huoshan_wanying/MedQbench/Project/202512_MedQ-UNI/MedQ-Uni
   source .venv/bin/activate
   ```

2. **ä¾èµ–æ£€æŸ¥**:
   - PyTorch >= 2.0
   - transformers, accelerate
   - safetensors
   - PIL, numpy, pandas
   - scikit-image (SSIM è®¡ç®—)
   - tqdm

### æ–¹æ³• 1: å•æ£€æŸ¥ç‚¹æµ‹è¯• (ver1)

**é€‚ç”¨åœºæ™¯**: å¿«é€Ÿæµ‹è¯•å•ä¸ªæ£€æŸ¥ç‚¹ï¼Œè°ƒè¯•æ¨ç†å‚æ•°

```bash
# ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
cd /mnt/shared-storage-user/quwanying/huoshan_wanying/MedQbench/Project/202512_MedQ-UNI/MedQ-Uni

# æ‰§è¡Œ ver1 è„šæœ¬ (ä¼šè‡ªåŠ¨ cd åˆ°æ­£ç¡®ç›®å½•)
bash inference_pipeline/MedQ-Uni_run_batch_test_ver1.sh
```

**è„šæœ¬å†…éƒ¨æµç¨‹**:
1. `cd` åˆ°é¡¹ç›®æ ¹ç›®å½• (line 9)
2. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
3. è®¾ç½®ç¯å¢ƒå˜é‡ (CUDA_VISIBLE_DEVICES, TOKENIZERS_PARALLELISM ç­‰)
4. å¾ªç¯å¤„ç†æ¯ä¸ªæ•°æ®é›†:
   - æ£€æŸ¥ annotation æ–‡ä»¶å­˜åœ¨æ€§
   - åˆ›å»ºæ—¶é—´æˆ³è¾“å‡ºç›®å½•
   - è°ƒç”¨ `python inference_pipeline/MedQ-Uni_run_batch_test2.py`
   - ä¿å­˜ç»“æœåˆ° `MedQ-Uni_results_16000/{DATASET}_{TIMESTAMP}/`

**è‡ªå®šä¹‰é…ç½®** (ä¿®æ”¹ ver1.sh):
```bash
# é€‰æ‹©ä¸åŒçš„ GPU
TARGET_GPU="0"  # é»˜è®¤æ˜¯ 3

# ä¿®æ”¹æ˜¾å­˜é™åˆ¶
MAX_MEM="80GiB"  # é»˜è®¤æ˜¯ 130GiB

# æ·»åŠ /åˆ é™¤æ•°æ®é›†
ANNOTATION_FILES=(
    "/path/to/your/dataset1.jsonl"
    "/path/to/your/dataset2.jsonl"
)

# é™åˆ¶æµ‹è¯•æ ·æœ¬æ•° (å¿«é€ŸéªŒè¯)
NUM_SAMPLES=10  # é»˜è®¤æ˜¯ 50
```

### æ–¹æ³• 2: å¤šæ£€æŸ¥ç‚¹å¹¶è¡Œæµ‹è¯• (ver2)

**é€‚ç”¨åœºæ™¯**: æ‰¹é‡è¯„ä¼°å¤šä¸ªæ£€æŸ¥ç‚¹ï¼Œå¯¹æ¯”ä¸åŒè®­ç»ƒé˜¶æ®µçš„æ€§èƒ½

```bash
# ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
cd /mnt/shared-storage-user/quwanying/huoshan_wanying/MedQbench/Project/202512_MedQ-UNI/MedQ-Uni

# æ‰§è¡Œ ver2 è„šæœ¬
bash inference_pipeline/MedQ-Uni_run_batch_test_ver2.sh
```

**è„šæœ¬å†…éƒ¨æµç¨‹**:
1. `cd` åˆ°é¡¹ç›®æ ¹ç›®å½• (line 11)
2. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
3. å¤–å±‚å¾ªç¯: éå†æ¯ä¸ªæ£€æŸ¥ç‚¹ (5 ä¸ª)
4. å†…å±‚å¾ªç¯: ä¸ºæ¯ä¸ª GPU åˆ†é…ä»»åŠ¡
   - GPU 0: å¤„ç†æ•°æ®é›† 0, 2, 4, 6, 8, 10 (å¶æ•°ç´¢å¼•)
   - GPU 1: å¤„ç†æ•°æ®é›† 1, 3, 5, 7, 9, 11 (å¥‡æ•°ç´¢å¼•)
5. å¹¶è¡Œæ‰§è¡Œ: ä¸¤ä¸ª GPU åŒæ—¶æ¨ç† (åå°è¿›ç¨‹)
6. ç­‰å¾…å½“å‰æ£€æŸ¥ç‚¹æ‰€æœ‰ä»»åŠ¡å®Œæˆ
7. GPU æ¸…ç†: ç­‰å¾… 15 ç§’åå¤„ç†ä¸‹ä¸€ä¸ªæ£€æŸ¥ç‚¹
8. ä¿å­˜æ—¥å¿—: `{BASE_OUTPUT_DIR}/{CHECKPOINT}/gpu_{GPU_ID}.log`

**ä»»åŠ¡åˆ†é…ç¤ºä¾‹** (å‡è®¾ 12 ä¸ªæ•°æ®é›†):
```
Checkpoint: 0004000
  GPU 0 åå°ä»»åŠ¡: dataset_0, dataset_2, dataset_4, ..., dataset_10
  GPU 1 åå°ä»»åŠ¡: dataset_1, dataset_3, dataset_5, ..., dataset_11
  ç­‰å¾…ä¸¤ä¸ª GPU å®Œæˆ

Checkpoint: 0008000
  GPU 0 åå°ä»»åŠ¡: ...
  GPU 1 åå°ä»»åŠ¡: ...
  ...
```

**è‡ªå®šä¹‰é…ç½®** (ä¿®æ”¹ ver2.sh):
```bash
# ä¿®æ”¹æ£€æŸ¥ç‚¹åˆ—è¡¨
CHECKPOINTS=(
    "/path/to/checkpoint1"
    "/path/to/checkpoint2"
)

# ä¿®æ”¹ GPU é…ç½®
GPUS=("0" "1" "2" "3")  # ä½¿ç”¨ 4 ä¸ª GPU

# ä¿®æ”¹æ•°æ®é›†åˆ—è¡¨
ANNOTATION_FILES=(
    "/path/to/dataset1.jsonl"
    # ...
)

# ä¿®æ”¹åŸºç¡€è¾“å‡ºç›®å½•
BASE_OUTPUT_DIR="my_experiment_results"
```

### æ–¹æ³• 3: ç»Ÿè®¡ç»“æœèšåˆ

æ¨ç†å®Œæˆåï¼Œä½¿ç”¨ `parse_statistics_to_csv.py` èšåˆæ‰€æœ‰ `statistics.json` æ–‡ä»¶:

```bash
# æ–¹å¼ A: ä½¿ç”¨è„šæœ¬å†…ç½®çš„é»˜è®¤è·¯å¾„
python inference_pipeline/parse_statistics_to_csv.py

# æ–¹å¼ B: æŒ‡å®šè‡ªå®šä¹‰è·¯å¾„
python inference_pipeline/parse_statistics_to_csv.py \
    -d ./MedQ-Uni_results_16000 \
    -d ./stage1_train_50_ver1 \
    -o my_summary.csv

# æ–¹å¼ C: å¯ç”¨è¯¦ç»†æ—¥å¿—
python inference_pipeline/parse_statistics_to_csv.py -v
```

**è¾“å‡ºç¤ºä¾‹** (`summary.csv`):
```csv
model_id,split,total_samples,psnr_mean,psnr_std,ssim_mean,ssim_std,avg_inference_time,task1_type,task1_count,task1_psnr_mean,...,timestamp
stage1_medq_2nodes_unif_combined_v1_0008000,test,100,28.45,3.21,0.876,0.043,1.23,denoising,50,29.12,...,2024-12-23T10:15:32
stage1_medq_2nodes_unif_combined_v1_0016000,test,100,29.87,2.98,0.891,0.038,1.18,denoising,50,30.45,...,2024-12-23T12:30:45
```

**è‡ªå®šä¹‰é»˜è®¤è·¯å¾„** (ä¿®æ”¹ parse_statistics_to_csv.py):
```python
# Line 29-32
DEFAULT_INPUT_DIRECTORIES = [
    "/your/custom/path/checkpoint_0008000",
    "/your/custom/path/checkpoint_0016000",
]
```

## ğŸ“Š è¾“å‡ºç»“æœ

### å•æ¬¡æ¨ç†è¾“å‡º (æ¯ä¸ªæ•°æ®é›†)

æ¯æ¬¡æ¨ç†ä¼šåœ¨è¾“å‡ºç›®å½•ä¸­ç”Ÿæˆä»¥ä¸‹æ–‡ä»¶:

```
{OUTPUT_DIR}/
â”œâ”€â”€ results.jsonl                  # æ¯ä¸ªæ ·æœ¬çš„è¯¦ç»†ç»“æœ (JSONL æ ¼å¼)
â”œâ”€â”€ statistics.json                # èšåˆç»Ÿè®¡æŒ‡æ ‡ (JSON æ ¼å¼)
â””â”€â”€ images/                        # ç”Ÿæˆçš„å›¾åƒæ–‡ä»¶
    â”œâ”€â”€ sample_0001.png
    â”œâ”€â”€ sample_0002.png
    â””â”€â”€ ...
```

#### results.jsonl æ ¼å¼
```jsonl
{"id": "sample_0001", "psnr": 28.45, "ssim": 0.876, "task_type": "denoising", "inference_time": 1.23}
{"id": "sample_0002", "psnr": 29.12, "ssim": 0.881, "task_type": "super_resolution", "inference_time": 1.18}
...
```

#### statistics.json æ ¼å¼
```json
{
  "overall": {
    "total_samples": 100,
    "psnr_mean": 28.45,
    "psnr_std": 3.21,
    "ssim_mean": 0.876,
    "ssim_std": 0.043,
    "avg_inference_time": 1.23
  },
  "by_task_type": {
    "denoising": {
      "count": 50,
      "psnr_mean": 29.12,
      "psnr_std": 2.87,
      "ssim_mean": 0.889,
      "ssim_std": 0.038
    },
    "super_resolution": {
      "count": 50,
      "psnr_mean": 27.78,
      "psnr_std": 3.45,
      "ssim_mean": 0.863,
      "ssim_std": 0.047
    }
  },
  "timestamp": "2024-12-23T10:15:32"
}
```

### ç›®å½•ç»“æ„ç¤ºä¾‹

#### ver1 è¾“å‡ºç»“æ„ (æ‰å¹³)
```
MedQ-Uni_results_16000/
â”œâ”€â”€ AAPM-CT-MAR_test_20241223_101532/
â”‚   â”œâ”€â”€ results.jsonl
â”‚   â”œâ”€â”€ statistics.json
â”‚   â””â”€â”€ images/
â”œâ”€â”€ AMIR_MRI_super-resolution_test_20241223_103045/
â”‚   â”œâ”€â”€ results.jsonl
â”‚   â”œâ”€â”€ statistics.json
â”‚   â””â”€â”€ images/
â””â”€â”€ ...
```

#### ver2 è¾“å‡ºç»“æ„ (åˆ†å±‚)
```
stage1_train_50_ver1/
â”œâ”€â”€ stage1_medq_2nodes_unif_combined_v1_0004000/
â”‚   â”œâ”€â”€ AAPM-CT-MAR_test/
â”‚   â”‚   â”œâ”€â”€ results.jsonl
â”‚   â”‚   â”œâ”€â”€ statistics.json
â”‚   â”‚   â””â”€â”€ images/
â”‚   â”œâ”€â”€ AMIR_MRI_super-resolution_test/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ gpu_0.log                    # GPU 0 çš„æ‰§è¡Œæ—¥å¿—
â”‚   â””â”€â”€ gpu_1.log                    # GPU 1 çš„æ‰§è¡Œæ—¥å¿—
â”œâ”€â”€ stage1_medq_2nodes_unif_combined_v1_0008000/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ stage1_medq_2nodes_unif_combined_v1_0012000/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ stage1_medq_2nodes_unif_combined_v1_0016000/
â”‚   â””â”€â”€ ...
â””â”€â”€ stage1_medq_2nodes_unif_combined_v1_0020000/
    â””â”€â”€ ...
```

### èšåˆåçš„ CSV è¾“å‡º

`parse_statistics_to_csv.py` ç”Ÿæˆçš„ `summary.csv`:

**åˆ—ç»“æ„**:
- åŸºç¡€åˆ—: `model_id`, `split`, `total_samples`, `psnr_mean`, `psnr_std`, `ssim_mean`, `ssim_std`, `avg_inference_time`
- ä»»åŠ¡åˆ— (åŠ¨æ€): `task1_type`, `task1_count`, `task1_psnr_mean`, `task1_psnr_std`, `task1_ssim_mean`, `task1_ssim_std`
- æ›´å¤šä»»åŠ¡: `task2_*`, `task3_*`, ... (æ ¹æ®å®é™…ä»»åŠ¡ç±»å‹æ•°é‡åŠ¨æ€ç”Ÿæˆ)
- æ—¶é—´æˆ³: `timestamp`

**ç¤ºä¾‹æ•°æ®**:
```csv
model_id,split,total_samples,psnr_mean,psnr_std,ssim_mean,ssim_std,avg_inference_time,task1_type,task1_count,task1_psnr_mean,task1_psnr_std,task1_ssim_mean,task1_ssim_std,task2_type,task2_count,task2_psnr_mean,task2_psnr_std,task2_ssim_mean,task2_ssim_std,timestamp
stage1_medq_2nodes_unif_combined_v1_0004000,test,100,26.32,3.45,0.854,0.052,1.45,denoising,50,27.15,3.12,0.867,0.048,super_resolution,50,25.49,3.67,0.841,0.055,2024-12-23T10:15:32
stage1_medq_2nodes_unif_combined_v1_0008000,test,100,28.45,3.21,0.876,0.043,1.23,denoising,50,29.12,2.87,0.889,0.038,super_resolution,50,27.78,3.45,0.863,0.047,2024-12-23T12:30:45
...
```

## âš™ï¸ æŠ€æœ¯è¯´æ˜

### Python è„šæœ¬å¯¼å…¥æœºåˆ¶

**å…³é”®ä»£ç ** (test1.py:43-54, test2.py:43-54):
```python
# UniMedVL imports
ROOT = "/inspire/hdd/global_user/hejunjun-24017/junzhin/projects/MedQ-Uni/"
sys.path.append(ROOT)

from data.transforms import ImageTransform
from data.data_utils import add_special_tokens, pil_img2rgb
from modeling.bagel import BagelConfig, Bagel, Qwen2Config, Qwen2ForCausalLM, ...
from modeling.qwen2 import Qwen2Tokenizer
from modeling.autoencoder import load_ae
from inferencer import InterleaveInferencer
```

**å·¥ä½œåŸç†**:
1. `ROOT` å®šä¹‰äº†å…±äº«æ¨¡å—åº“çš„ç»å¯¹è·¯å¾„
2. `sys.path.append(ROOT)` å°†è¯¥è·¯å¾„æ·»åŠ åˆ° Python æ¨¡å—æœç´¢è·¯å¾„
3. åç»­çš„ `from data.xxx import yyy` ä¼šä» ROOT è·¯å¾„ä¸‹æŸ¥æ‰¾æ¨¡å—

**é‡è¦ç‰¹æ€§**:
- âœ… ROOT æ˜¯ç»å¯¹è·¯å¾„ï¼Œä¸å—è„šæœ¬æ‰€åœ¨ä½ç½®å½±å“
- âœ… ç§»åŠ¨è„šæœ¬åˆ° `inference_pipeline/` ä¸ä¼šç ´åå¯¼å…¥
- âœ… æ— éœ€ä¿®æ”¹ä»»ä½• Python å¯¼å…¥è¯­å¥

**ä¸ºä»€ä¹ˆä½¿ç”¨ä¸¤ä¸ªä¸åŒçš„è·¯å¾„?**
- **å…±äº«æ¨¡å—åº“**: `/inspire/hdd/.../MedQ-Uni/` (å­˜æ”¾ data, modeling, inferencer æ¨¡å—)
- **é¡¹ç›®å·¥ä½œç›®å½•**: `/mnt/shared-storage-user/.../MedQ-Uni/` (å­˜æ”¾è„šæœ¬ã€æ•°æ®ã€ç»“æœ)

è¿™ç§è®¾è®¡å…è®¸å¤šä¸ªé¡¹ç›®å…±äº«åŒä¸€å¥—æ¨¡å‹ä»£ç åº“ï¼ŒåŒæ—¶ä¿æŒå„è‡ªç‹¬ç«‹çš„æ•°æ®å’Œå®éªŒç»“æœã€‚

### Shell è„šæœ¬æ‰§è¡Œæµç¨‹

**å…³é”®æœºåˆ¶** (ver1.sh:9, ver2.sh:11):
```bash
cd /mnt/shared-storage-user/quwanying/huoshan_wanying/MedQbench/Project/202512_MedQ-UNI/MedQ-Uni
```

**å·¥ä½œåŸç†**:
1. Shell è„šæœ¬é¦–å…ˆ `cd` åˆ°é¡¹ç›®æ ¹ç›®å½• (ç»å¯¹è·¯å¾„)
2. ç„¶åè°ƒç”¨ `python inference_pipeline/MedQ-Uni_run_batch_test2.py` (ç›¸å¯¹äºæ ¹ç›®å½•)
3. Python è„šæœ¬å†…éƒ¨ä½¿ç”¨ç»å¯¹è·¯å¾„ `ROOT` å¯¼å…¥æ¨¡å—

**é‡è¦è¯´æ˜**:
- âš ï¸ Shell è„šæœ¬åº”è¯¥ä»ä»»æ„ä½ç½®è¿è¡Œï¼Œå®ƒä¼šè‡ªåŠ¨ `cd` åˆ°æ­£ç¡®ä½ç½®
- âš ï¸ è¾“å‡ºç›®å½• (å¦‚ `BASE_OUTPUT_DIR="MedQ-Uni_results_16000"`) æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œä¼šåœ¨æ ¹ç›®å½•åˆ›å»º
- âœ… ä¿®æ”¹åçš„ Shell è„šæœ¬å·²æ›´æ–° Python è°ƒç”¨è·¯å¾„ä¸º `inference_pipeline/...`

### ç»Ÿè®¡æ•°æ®å¤„ç†æµç¨‹

**parse_statistics_to_csv.py å¤„ç†æµç¨‹**:

1. **ç¬¬ä¸€éæ‰«æ** (ç¡®å®šæœ€å¤§ä»»åŠ¡ç±»å‹æ•°é‡):
   ```python
   def determine_max_task_count(json_files):
       max_tasks = 0
       for file in json_files:
           data = json.load(file)
           max_tasks = max(max_tasks, len(data['by_task_type']))
       return max_tasks
   ```

2. **ç”Ÿæˆåˆ—å** (åŠ¨æ€åˆ—):
   ```python
   def generate_column_names(max_tasks):
       columns = ['model_id', 'split', 'total_samples', ...]
       for i in range(1, max_tasks + 1):
           columns += [f'task{i}_type', f'task{i}_count', ...]
       return columns
   ```

3. **ç¬¬äºŒéæ‰«æ** (è§£ææ•°æ®):
   - æå–å…ƒæ•°æ® (model_id, split)
   - è§£æ overall æŒ‡æ ‡
   - æ¨ªå‘å±•å¼€ by_task_type (æŒ‰å­—æ¯é¡ºåºæ’åº)
   - å¡«å……ç©ºç™½åˆ— (å¦‚æœæŸæ–‡ä»¶ä»»åŠ¡æ•°å°‘äº max_tasks)

4. **è¾“å‡º CSV**:
   ```python
   df = pd.DataFrame(rows, columns=columns)
   df.to_csv(output_csv, index=False)
   ```

**å¤„ç†ç¤ºä¾‹**:
```
è¾“å…¥:
- file1.json: 1 ä¸ªä»»åŠ¡ç±»å‹ (denoising)
- file2.json: 2 ä¸ªä»»åŠ¡ç±»å‹ (denoising, super_resolution)
- file3.json: 3 ä¸ªä»»åŠ¡ç±»å‹ (denoising, super_resolution, restoration)

ç¬¬ä¸€éæ‰«æ -> max_tasks = 3

ç”Ÿæˆåˆ—å -> [..., task1_*, task2_*, task3_*]

ç¬¬äºŒéæ‰«æ:
- file1 -> task1=denoising, task2=ç©º, task3=ç©º
- file2 -> task1=denoising, task2=super_resolution, task3=ç©º
- file3 -> task1=denoising, task2=restoration, task3=super_resolution
```

## ğŸ“‹ ä¾èµ–è¦æ±‚

### Python ç¯å¢ƒ
- Python >= 3.8
- PyTorch >= 2.0 (CUDA æ”¯æŒ)

### æ ¸å¿ƒä¾èµ–
```txt
torch>=2.0.0
transformers>=4.30.0
accelerate>=0.20.0
safetensors>=0.3.0
Pillow>=9.0.0
numpy>=1.21.0
pandas>=1.3.0
scikit-image>=0.19.0  # SSIM è®¡ç®—
tqdm>=4.62.0
```

### ç³»ç»Ÿè¦æ±‚
- GPU: NVIDIA GPU with CUDA support (æ¨è 24GB+ æ˜¾å­˜)
- ç£ç›˜: å……è¶³çš„å­˜å‚¨ç©ºé—´ç”¨äºä¿å­˜æ¨ç†ç»“æœå’Œå›¾åƒ
- å†…å­˜: å»ºè®® 32GB+ RAM

### å®‰è£…ä¾èµ–
```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate

# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
pip install transformers accelerate safetensors
pip install Pillow numpy pandas scikit-image tqdm
```

## ğŸ“ å¸¸è§é—®é¢˜ (FAQ)

### Q1: å¦‚ä½•é€‰æ‹© test1.py è¿˜æ˜¯ test2.py?
**A**: ä¸¤è€…çš„åŒºåˆ«ä»…åœ¨äº VAE transform çš„ min_size å‚æ•°:
- `test2.py` (min=256): æ›´å¿«ï¼Œæ˜¾å­˜å ç”¨å°ï¼Œé€‚åˆå¿«é€Ÿæµ‹è¯•
- `test1.py` (min=512): ä¿ç•™æ›´å¤šç»†èŠ‚ï¼Œé€‚åˆæœ€ç»ˆè¯„ä¼°

æ¨èä½¿ç”¨ `test2.py` (ver1.sh å’Œ ver2.sh é»˜è®¤éƒ½è°ƒç”¨ test2.py)ã€‚

### Q2: å¦‚ä½•ä¿®æ”¹è¦æµ‹è¯•çš„æ•°æ®é›†?
**A**: ç¼–è¾‘å¯¹åº”çš„ Shell è„šæœ¬ (ver1.sh æˆ– ver2.sh):
```bash
# ä¿®æ”¹ ANNOTATION_FILES æ•°ç»„
ANNOTATION_FILES=(
    "/path/to/your/dataset1.jsonl"
    "/path/to/your/dataset2.jsonl"
)
```

### Q3: å¦‚ä½•ä½¿ç”¨ä¸åŒçš„ GPU?
**A**:
- **ver1.sh**: ä¿®æ”¹ `TARGET_GPU="3"` ä¸ºä½ æƒ³è¦çš„ GPU ç¼–å·
- **ver2.sh**: ä¿®æ”¹ `GPUS=("0" "1")` æ•°ç»„

### Q4: æ¨ç†é€Ÿåº¦å¤ªæ…¢æ€ä¹ˆåŠ?
**A**:
1. å‡å°‘ `NUM_SAMPLES` (æµ‹è¯•æ›´å°‘æ ·æœ¬)
2. ä½¿ç”¨ `test2.py` (min_size=256, æ›´å¿«)
3. å¢åŠ  GPU æ•°é‡ (ver2.sh æ”¯æŒå¤š GPU å¹¶è¡Œ)
4. è°ƒæ•´ `max_mem_per_gpu` (å¢å¤§æ˜¾å­˜åˆ†é…)

### Q5: å¦‚ä½•æ·»åŠ æ–°çš„æ£€æŸ¥ç‚¹åˆ° ver2.sh?
**A**: ä¿®æ”¹ `CHECKPOINTS` æ•°ç»„:
```bash
CHECKPOINTS=(
    "/path/to/checkpoint1"
    "/path/to/checkpoint2"
    "/path/to/your/new/checkpoint"
)
```

### Q6: parse_statistics_to_csv.py æ‰¾ä¸åˆ°æ–‡ä»¶æ€ä¹ˆåŠ?
**A**:
1. æ£€æŸ¥é»˜è®¤è·¯å¾„é…ç½® (parse_statistics_to_csv.py:29-32)
2. ä½¿ç”¨ `-d` å‚æ•°æ‰‹åŠ¨æŒ‡å®šç›®å½•:
   ```bash
   python inference_pipeline/parse_statistics_to_csv.py -d /your/results/path
   ```

### Q7: å¦‚ä½•å¤„ç† CUDA Out of Memory é”™è¯¯?
**A**:
1. å‡å°‘ `max_mem_per_gpu` å€¼
2. å‡å°‘ batch size (å¦‚æœè„šæœ¬æ”¯æŒ)
3. ä½¿ç”¨ `test2.py` (min_size=256, æ˜¾å­˜å ç”¨æ›´å°)
4. å…³é—­å…¶ä»–å ç”¨ GPU çš„è¿›ç¨‹

### Q8: å¦‚ä½•å¹¶è¡Œå¤„ç†æ›´å¤š GPU (ver2.sh)?
**A**: ä¿®æ”¹ `GPUS` æ•°ç»„:
```bash
# ä½¿ç”¨ 4 ä¸ª GPU
GPUS=("0" "1" "2" "3")
```
è„šæœ¬ä¼šè‡ªåŠ¨è¿›è¡Œè½®è¯¢ä»»åŠ¡åˆ†é…ã€‚

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜ 1: ModuleNotFoundError
```
ModuleNotFoundError: No module named 'data'
```
**åŸå› **: sys.path æ²¡æœ‰æ­£ç¡®æ·»åŠ  ROOT è·¯å¾„
**è§£å†³**: æ£€æŸ¥ Python è„šæœ¬çš„ ROOT è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œç¡®ä¿ `/inspire/hdd/.../MedQ-Uni/` è·¯å¾„å­˜åœ¨ä¸”åŒ…å« `data`, `modeling`, `inferencer` æ¨¡å—

### é—®é¢˜ 2: Shell è„šæœ¬æ‰¾ä¸åˆ° Python è„šæœ¬
```
python: can't open file 'MedQ-Uni_run_batch_test2.py': [Errno 2] No such file or directory
```
**åŸå› **: Shell è„šæœ¬æ²¡æœ‰ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼Œæˆ– Python è·¯å¾„æœªæ›´æ–°
**è§£å†³**: ç¡®ä¿ Shell è„šæœ¬å·²æ›´æ–°ä¸º `python inference_pipeline/MedQ-Uni_run_batch_test2.py`

### é—®é¢˜ 3: parse_statistics_to_csv.py è¾“å‡ºä¸ºç©º
```
WARNING: No statistics.json files found
```
**åŸå› **: é»˜è®¤è·¯å¾„ä¸æ­£ç¡®ï¼Œæˆ–æ¨ç†å°šæœªå®Œæˆ
**è§£å†³**:
1. ç¡®è®¤æ¨ç†å·²å®Œæˆå¹¶ç”Ÿæˆ `statistics.json`
2. ä½¿ç”¨ `-v` æŸ¥çœ‹è¯¦ç»†æ—¥å¿—: `python parse_statistics_to_csv.py -v`
3. æ‰‹åŠ¨æŒ‡å®šè·¯å¾„: `python parse_statistics_to_csv.py -d /your/results/path`

## ğŸ“Œ æœ€ä½³å®è·µ

1. **æµ‹è¯•æµç¨‹**:
   - å…ˆç”¨ ver1.sh æµ‹è¯•å•ä¸ªæ£€æŸ¥ç‚¹ï¼Œç¡®ä¿é…ç½®æ­£ç¡®
   - å†ç”¨ ver2.sh æ‰¹é‡å¤„ç†å¤šä¸ªæ£€æŸ¥ç‚¹

2. **GPU ç®¡ç†**:
   - ä½¿ç”¨ `nvidia-smi` ç›‘æ§ GPU ä½¿ç”¨æƒ…å†µ
   - åˆç†åˆ†é… GPU (é¿å…è¿‡è½½)
   - ver2.sh ä¼šåœ¨æ£€æŸ¥ç‚¹é—´ç­‰å¾… 15 ç§’ï¼Œå…è®¸ GPU æ¸…ç†æ˜¾å­˜

3. **ç»“æœç®¡ç†**:
   - å®šæœŸå¤‡ä»½æ¨ç†ç»“æœ
   - ä½¿ç”¨ `parse_statistics_to_csv.py` åŠæ—¶èšåˆç»Ÿè®¡æ•°æ®
   - ä½¿ç”¨æœ‰æ„ä¹‰çš„è¾“å‡ºç›®å½•åç§°

4. **è°ƒè¯•æŠ€å·§**:
   - ä½¿ç”¨ `NUM_SAMPLES=10` å¿«é€ŸéªŒè¯
   - ä½¿ç”¨ `--verbose` æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
   - æ£€æŸ¥ `gpu_*.log` æ—¥å¿—æ–‡ä»¶æ’æŸ¥é—®é¢˜

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è”ç³»é¡¹ç›®ç»´æŠ¤è€…æˆ–æäº¤ Issueã€‚

---

**æœ€åæ›´æ–°**: 2024-12-23
**ç»´æŠ¤è€…**: MedQ-Uni Team
